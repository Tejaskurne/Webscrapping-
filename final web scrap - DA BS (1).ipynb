{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add2309e-aafb-4e59-9025-1fbb42644888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved for URL_ID:bctech2011.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2012.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2013.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2014.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2015.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2016.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2017.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2018.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2019.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2020.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2021.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2022.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2023.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2024.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2025.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2026.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2027.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2028.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2029.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2030.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2031.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2032.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2033.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2034.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2035.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2036.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2037.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2038.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2039.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2040.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2041.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2042.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2043.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2044.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2045.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2046.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2047.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2048.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2049.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2050.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2051.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2052.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2053.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2054.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2055.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2056.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2057.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2058.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2059.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2060.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2061.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2062.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2063.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2064.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2065.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2066.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2067.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2068.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2069.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2070.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2071.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2072.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2073.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2074.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2075.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2076.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2077.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2078.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2079.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2080.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2081.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2082.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2083.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2084.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2085.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2086.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2087.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2088.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2089.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2090.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2091.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2092.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2093.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2094.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2095.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2096.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2097.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2098.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2099.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2100.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2101.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2102.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2103.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2104.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2105.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2106.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2107.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2108.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2109.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2110.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2111.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2112.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2113.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2114.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2115.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2116.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2117.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2118.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2119.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2120.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2121.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2122.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2123.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2124.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2125.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2126.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2127.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2128.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2129.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2130.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2131.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2132.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2133.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2134.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2135.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2136.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2137.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2138.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2139.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2140.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2141.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2142.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2143.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2144.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2145.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2146.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2147.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2148.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2149.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2150.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2151.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2152.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2153.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2154.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2155.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2156.txt\n",
      " Code Executed\n",
      "Data extracted and saved for URL_ID:bctech2157.txt\n",
      " Code Executed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_excel(r\"C:\\Users\\tejas\\Downloads\\20211030 Test Assignment-20241016T161448Z-001\\20211030 Test Assignment\\Input.xlsx\")\n",
    "\n",
    "# Create a directory for saving extracted files\n",
    "output_folder = (r\"C:\\Users\\tejas\\OneDrive\\Desktop\\extracted text\")\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "def extract_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            title = soup.find('h1', class_='entry-title')\n",
    "            title_text = title.get_text(strip=True) if title else 'No title found'\n",
    "\n",
    "            content = soup.find(class_='td-ss-main-content')\n",
    "            extracted_text = ''\n",
    "            if content:\n",
    "\n",
    "                extracted_texts = set()\n",
    "\n",
    "                for tag in content.find_all(['h1', 'h3', 'p', 'li']):\n",
    "                    text = tag.get_text(strip=True)\n",
    "\n",
    "                    if text and text not in extracted_texts:\n",
    "                        extracted_text += text + '\\n'\n",
    "                        extracted_texts.add(text)\n",
    "            return title_text, extracted_text\n",
    "        else:\n",
    "            return 'Failed to retrieve webpage', ''\n",
    "    except Exception as e:\n",
    "        return f'Error occurred: {e}', ''\n",
    "\n",
    "def save_to_file(url_id, title, content):\n",
    "    file_name = os.path.join(output_folder, f'{url_id}.txt')  # Use the output folder path\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(f\"Title: {title}\\n\\n\")\n",
    "        file.write(content)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    url = row['URL']\n",
    "    url_id = row['URL_ID']\n",
    "\n",
    "    title, content = extract_data(url)\n",
    "\n",
    "    save_to_file(url_id, title, content)\n",
    "\n",
    "    print(f\"Data extracted and saved for URL_ID:\" f\"{url_id}.txt\")\n",
    "    print(\" Code Executed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "674217d2-277b-4bd0-80c1-ba97350caee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tejas\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\tejas\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\tejas\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tejas\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tejas\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\tejas\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e369e9b3-a39c-4114-8ebf-15b527b1ccd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>49</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.088993</td>\n",
       "      <td>11.119792</td>\n",
       "      <td>51.241218</td>\n",
       "      <td>24.944404</td>\n",
       "      <td>11.119792</td>\n",
       "      <td>1094</td>\n",
       "      <td>2135</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>bctech2011</td>\n",
       "      <td>https://insights.blackcoffer.com/ml-and-ai-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>7.615385</td>\n",
       "      <td>44.191919</td>\n",
       "      <td>20.722922</td>\n",
       "      <td>7.615385</td>\n",
       "      <td>175</td>\n",
       "      <td>396</td>\n",
       "      <td>2.722222</td>\n",
       "      <td>1</td>\n",
       "      <td>7.939394</td>\n",
       "      <td>bctech2012</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>13.342857</td>\n",
       "      <td>37.687366</td>\n",
       "      <td>20.412089</td>\n",
       "      <td>13.342857</td>\n",
       "      <td>176</td>\n",
       "      <td>467</td>\n",
       "      <td>2.456103</td>\n",
       "      <td>1</td>\n",
       "      <td>7.505353</td>\n",
       "      <td>bctech2013</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>7.226415</td>\n",
       "      <td>43.864230</td>\n",
       "      <td>20.436258</td>\n",
       "      <td>7.226415</td>\n",
       "      <td>168</td>\n",
       "      <td>383</td>\n",
       "      <td>2.613577</td>\n",
       "      <td>1</td>\n",
       "      <td>7.634465</td>\n",
       "      <td>bctech2014</td>\n",
       "      <td>https://insights.blackcoffer.com/effective-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>14.034483</td>\n",
       "      <td>43.488943</td>\n",
       "      <td>23.009370</td>\n",
       "      <td>14.034483</td>\n",
       "      <td>177</td>\n",
       "      <td>407</td>\n",
       "      <td>2.520885</td>\n",
       "      <td>1</td>\n",
       "      <td>7.400491</td>\n",
       "      <td>bctech2015</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0             141              49        0.484211            0.088993   \n",
       "1              21               6        0.555556            0.068182   \n",
       "2              21              10        0.354839            0.066381   \n",
       "3              12               7        0.263158            0.049608   \n",
       "4              15               3        0.666667            0.044226   \n",
       "\n",
       "   AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            11.119792                    51.241218  24.944404   \n",
       "1             7.615385                    44.191919  20.722922   \n",
       "2            13.342857                    37.687366  20.412089   \n",
       "3             7.226415                    43.864230  20.436258   \n",
       "4            14.034483                    43.488943  23.009370   \n",
       "\n",
       "   AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                         11.119792                1094        2135   \n",
       "1                          7.615385                 175         396   \n",
       "2                         13.342857                 176         467   \n",
       "3                          7.226415                 168         383   \n",
       "4                         14.034483                 177         407   \n",
       "\n",
       "   SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH      URL_ID  \\\n",
       "0           2.714286                  2         7.800000  bctech2011   \n",
       "1           2.722222                  1         7.939394  bctech2012   \n",
       "2           2.456103                  1         7.505353  bctech2013   \n",
       "3           2.613577                  1         7.634465  bctech2014   \n",
       "4           2.520885                  1         7.400491  bctech2015   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://insights.blackcoffer.com/ml-and-ai-bas...  \n",
       "1  https://insights.blackcoffer.com/streamlined-i...  \n",
       "2  https://insights.blackcoffer.com/efficient-dat...  \n",
       "3  https://insights.blackcoffer.com/effective-man...  \n",
       "4  https://insights.blackcoffer.com/streamlined-t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "class TextAnalyzer:\n",
    "    def __init__(self, stopwords_folder, positive_file, negative_file):\n",
    "        # Load word lists efficiently using set comprehension\n",
    "        self.stop_words = {\n",
    "            word.strip() \n",
    "            for file in os.listdir(stopwords_folder) \n",
    "            if file.endswith('.txt')\n",
    "            for word in open(os.path.join(stopwords_folder, file), 'r', encoding='utf-8', errors='ignore')\n",
    "            if word.strip()\n",
    "        }\n",
    "        \n",
    "        # Load sentiment words\n",
    "        self.positive_words = {word.strip() for word in open(positive_file, 'r', encoding='utf-8', errors='ignore') if word.strip()}\n",
    "        self.negative_words = {word.strip() for word in open(negative_file, 'r', encoding='utf-8', errors='ignore') if word.strip()}\n",
    "        \n",
    "        self.pronouns_pattern = re.compile(r'\\b(I|we|my|ours|us)\\b', re.IGNORECASE)\n",
    "        self.clean_pattern = re.compile(r'[^\\w\\s.]')\n",
    "        self.digits_pattern = re.compile(r'\\d+')\n",
    "\n",
    "    def analyze_text(self, text):\n",
    "        # Clean text and tokenize in one pass\n",
    "        clean_text = self.digits_pattern.sub('', self.clean_pattern.sub(' ', text.lower()))\n",
    "        sentences = sent_tokenize(clean_text)\n",
    "        words = [word for word in word_tokenize(clean_text) \n",
    "                if word not in self.stop_words and word not in punctuation]\n",
    "        \n",
    "        word_count = len(words)\n",
    "        sentence_count = len(sentences)\n",
    "        \n",
    "        if word_count == 0 or sentence_count == 0:\n",
    "            return self._empty_results()\n",
    "        \n",
    "        # Calculate scores using generator expressions\n",
    "        positive_score = sum(1 for word in words if word in self.positive_words)\n",
    "        negative_score = sum(1 for word in words if word in self.negative_words)\n",
    "        \n",
    "        # Calculate complex words and syllables in single pass\n",
    "        complex_count = 0\n",
    "        total_syllables = 0\n",
    "        total_chars = 0\n",
    "        \n",
    "        for word in words:\n",
    "            syllables = self._count_syllables(word)\n",
    "            total_syllables += syllables\n",
    "            if syllables > 2:\n",
    "                complex_count += 1\n",
    "            total_chars += len(word)\n",
    "        \n",
    "      \n",
    "        avg_sent_len = word_count / sentence_count\n",
    "        percent_complex = (complex_count / word_count) * 100\n",
    "        \n",
    "        return {\n",
    "            'POSITIVE SCORE': positive_score,\n",
    "            'NEGATIVE SCORE': negative_score,\n",
    "            'POLARITY SCORE': (positive_score - negative_score) / (positive_score + negative_score + 0.000001),\n",
    "            'SUBJECTIVITY SCORE': (positive_score + negative_score) / (word_count + 0.000001),\n",
    "            'AVG SENTENCE LENGTH': avg_sent_len,\n",
    "            'PERCENTAGE OF COMPLEX WORDS': percent_complex,\n",
    "            'FOG INDEX': 0.4 * (avg_sent_len + percent_complex),\n",
    "            'AVG NUMBER OF WORDS PER SENTENCE': avg_sent_len,\n",
    "            'COMPLEX WORD COUNT': complex_count,\n",
    "            'WORD COUNT': word_count,\n",
    "            'SYLLABLE PER WORD': total_syllables / word_count,\n",
    "            'PERSONAL PRONOUNS': len(self.pronouns_pattern.findall(text)),\n",
    "            'AVG WORD LENGTH': total_chars / word_count\n",
    "        }\n",
    "\n",
    "    def _count_syllables(self, word):\n",
    "        if word.endswith(('es', 'ed')):\n",
    "            word = word[:-2]\n",
    "        count = len([i for i, char in enumerate(word) \n",
    "                    if char in 'aeiouy' and (i == 0 or word[i-1] not in 'aeiouy')])\n",
    "        return max(1, count)\n",
    "\n",
    "    def _empty_results(self):\n",
    "        return {key: 0 for key in [\n",
    "            'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE',\n",
    "            'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
    "            'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
    "            'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH'\n",
    "        ]}\n",
    "\n",
    "def analyze_files(text_folder, stopwords_folder, positive_file, negative_file, input_excel):\n",
    "    analyzer = TextAnalyzer(stopwords_folder, positive_file, negative_file)\n",
    "    url_df = pd.read_excel(input_excel)\n",
    "    \n",
    "    results = []\n",
    "    for file_name in os.listdir(text_folder):\n",
    "        if file_name.endswith('.txt'):\n",
    "            url_id = file_name[:-4]\n",
    "            with open(os.path.join(text_folder, file_name), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                analysis = analyzer.analyze_text(f.read())\n",
    "                analysis['URL_ID'] = url_id\n",
    "                results.append(analysis)\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_merged = pd.merge(df_results, url_df, on='URL_ID', how='left')\n",
    "    \n",
    "    columns = ['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
    "               'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS',\n",
    "               'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT',\n",
    "               'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']\n",
    "    \n",
    "    df_merged[columns].to_excel('Output Data Structure.xlsx', index=False)\n",
    "    return df_merged\n",
    "\n",
    "TEXT_FOLDER = (r\"C:\\Users\\tejas\\OneDrive\\Desktop\\extracted text\")  \n",
    "STOPWORDS_FOLDER = (r\"C:\\Users\\tejas\\Downloads\\20211030 Test Assignment-20241016T161448Z-001\\20211030 Test Assignment\\StopWords\")  \n",
    "POSITIVE_WORDS_FILE = (r\"C:\\Users\\tejas\\Downloads\\20211030 Test Assignment-20241016T161448Z-001\\20211030 Test Assignment\\MasterDictionary\\positive-words.txt\")  \n",
    "NEGATIVE_WORDS_FILE = (r\"C:\\Users\\tejas\\Downloads\\20211030 Test Assignment-20241016T161448Z-001\\20211030 Test Assignment\\MasterDictionary\\negative-words.txt\")  \n",
    "INPUT_EXCEL = (r\"C:\\Users\\tejas\\Downloads\\20211030 Test Assignment-20241016T161448Z-001\\20211030 Test Assignment\\Input.xlsx\")  \n",
    "\n",
    "results_df = analyze_files(\n",
    "    TEXT_FOLDER,\n",
    "    STOPWORDS_FOLDER,\n",
    "    POSITIVE_WORDS_FILE,\n",
    "    NEGATIVE_WORDS_FILE,\n",
    "    INPUT_EXCEL\n",
    ")\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ef18f-3896-416f-bc8d-c95462292161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1ecfc-f7ad-4aef-8e12-98fc63c9d92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
